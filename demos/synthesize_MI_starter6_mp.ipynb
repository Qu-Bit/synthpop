{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import multiprocessing as mp\n",
    "\n",
    "from output_check2 import output_check\n",
    "from synthpop.recipes.starter6_tenure_agehead import Starter\n",
    "starter_ver='6'\n",
    "\n",
    "from synthpop.synthesizer import synthesize_all, enable_logging \n",
    "import pandas as pd\n",
    "import os,time,datetime\n",
    "import pickle\n",
    "\n",
    "import gc\n",
    "\n",
    "\n",
    "\n",
    "outputfolder='/home/da/tools/synthpop/demos/outputs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesize by county "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-04-20 11:12:09.444495\n",
      "\n",
      " county =  Wayne County  phase =  0 \n",
      "\n",
      "Synthesizing at geog level: 'block_group' (number of geographies is 1822)\n",
      "memory 1 154173440\n",
      "multiprocessing time in seconds:  2069.06460905\n",
      "memory multiprocessing end 6150914048\n",
      "result produce time in seconds:  2094.909266\n",
      "memory result end 12515733504\n",
      "\n",
      " county =  Wayne County  phase =  1 \n",
      "\n",
      "Synthesizing at geog level: 'block_group' (number of geographies is 1822)\n",
      "memory 1 6875922432\n",
      "multiprocessing time in seconds:  2508.90342498\n",
      "memory multiprocessing end 12716265472\n",
      "result produce time in seconds:  2547.23232603\n",
      "memory result end 18515197952\n",
      "\n",
      " county =  Wayne County  phase =  2 \n",
      "\n",
      "Synthesizing at geog level: 'block_group' (number of geographies is 1822)\n",
      "memory 1 7297208320\n",
      "multiprocessing time in seconds:  2117.79833388\n",
      "memory multiprocessing end 12675231744\n",
      "result produce time in seconds:  2156.74073601\n",
      "memory result end 18586238976\n",
      "total time 7768.42633319\n",
      "2016-04-20 13:21:37.870831\n"
     ]
    }
   ],
   "source": [
    "#for whole county\n",
    "time0=time.time()\n",
    "print str( datetime.datetime.now())\n",
    "results=[]\n",
    "\n",
    "#synthesize_counties([\"Livingston County\",\"Oakland County\",\"Washtenaw County\",\"Wayne County\",\"Monroe County\",\"Macomb County\",\"St. Clair County\"])\n",
    "if __name__=='__main__':\n",
    "    counties=[\"Wayne County\"]\n",
    "    finalcheck=[]\n",
    "    for county in counties:\n",
    "        phases=3\n",
    "        df_check=None\n",
    "        for phase in range(phases):\n",
    "            print \"\\n county = \",county,\" phase = \", phase, \"\\n\"\n",
    "            \n",
    "            pathout=outputfolder+county+\"_starter%s_\"%(starter_ver) #output folder\n",
    "            \n",
    "            starter = Starter(os.environ[\"CENSUS\"], \"MI\", county, phase=phase)\n",
    "           \n",
    "            households, persons, fit, hh_marginal, pp_marginal = synthesize_all(starter)\n",
    "\n",
    "            #households.index.name='hh_id' #result[0] is hh\n",
    "            #households['serialno'] = households['serialno'].map(lambda x: '%f' % x)\n",
    "            #persons['serialno'] = persons['serialno'].map(lambda x: '%f' % x)\n",
    "            #results[0].to_csv(outputfolder+county+\"_starter%s_\"%('3')+\"HHs.csv\",float_format='%.f') #float_format, not use scentific, pplies to all fp numbers \n",
    "            #could use results['serialno'] = results['serialno'].map(lambda x: '%f' % x) to change output format for serialno only\n",
    "            \n",
    "            #HHs and Persons output\n",
    "            if phase == phases-1:\n",
    "                households.to_csv(pathout+'_households.csv')\n",
    "                persons.to_csv(pathout+'_persons.csv')\n",
    "\n",
    "\n",
    "            ##process check tables\n",
    "            dict_check=output_check({'households':[hh_marginal,households], 'persons':[pp_marginal,persons]})\n",
    "            #print dict_check.keys() #['households', 'persons', 'hhsize', 'person_factor', 'hhsize7plus']\n",
    "\n",
    "            outfiles=[pathout+\"_check_households.csv\",pathout+\"_check_households_bycat.csv\", \\\n",
    "                      pathout+\"_check_persons.csv\",pathout+\"_check_persons_bycat.csv\", \\\n",
    "                      pathout+\"_check_hhsize.csv\"]\n",
    "\n",
    "            #set index to check tables and rename columns with phase #\n",
    "            dfcheck=[dict_check['households'][0],dict_check['households'][1], \\\n",
    "                     dict_check['persons'][0],dict_check['persons'][1], \\\n",
    "                     dict_check['hhsize']]\n",
    "            indx=['state','county','tract','block group','cat_name']\n",
    "            indxl=[indx, indx+['cat_value']]*2+[indx+['hh_size']]\n",
    "\n",
    "            for ind, df in zip(indxl, dfcheck):\n",
    "                df.set_index(ind, inplace=True)\n",
    "                df.rename(columns={col:col+\"_\"+str(phase) for col in df.columns}, inplace=True)\n",
    "\n",
    "            #join check table from multiple runs            \n",
    "            if len(finalcheck)==0:\n",
    "                finalcheck=dfcheck\n",
    "            else:\n",
    "                for i in range(5):\n",
    "                    finalcheck[i]=pd.merge(finalcheck[i], dfcheck[i], left_index=True, right_index=True, how='left')\n",
    "\n",
    "            #create additional id fields for analysis purpose  \n",
    "            if phase == phases-1:\n",
    "                for i in range(5):\n",
    "                    finalcheck[i].reset_index(inplace=True)\n",
    "                    finalcheck[i]['bg10']=finalcheck[i]['tract']+finalcheck[i]['block group']\n",
    "                    finalcheck[i]['geoid10']=finalcheck[i]['state']+finalcheck[i]['county']+ \\\n",
    "                                                finalcheck[i]['tract']+finalcheck[i]['block group']  \n",
    "                    finalcheck[i].to_csv(outfiles[i])\n",
    "\n",
    "            if phase == 0:\n",
    "                dict_check['hhsize7plus'].to_csv(\"hh7_persons_drawing.csv\")\n",
    "            if phase == 1:\n",
    "                dict_check['person_factor'].to_csv(\"hh_size_person_factor.csv\")\n",
    "            if phase == 2:\n",
    "                os.rename(\"hh7_persons_drawing.csv\", pathout+\"_hh7_persons_drawing.csv\")\n",
    "                os.rename(\"hh_size_person_factor.csv\", pathout+\"_hh_size_person_factor.csv\")\n",
    "\n",
    "            households,persons,marginals,dict_check = None, None, None, None\n",
    "            \n",
    "\n",
    "            with open(pathout+'_fit_stats.pkl', 'wb') as f:\n",
    "                pickle.dump(fit, f)\n",
    "\n",
    "            del households,persons,hh_marginal,pp_marginal,dict_check, dfcheck\n",
    "            \n",
    "            gc.collect()  \n",
    "            \n",
    "print 'total time', time.time()-time0\n",
    "print str( datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesize by selected Block Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "phase =  0 \n",
      "\n",
      "Synthesizing at geog level: 'block_group' (number of geographies is 627)\n",
      "memory 1 132161536\n",
      "multiprocessing time in seconds:  18.5763170719\n",
      "memory multiprocessing end 151085056\n",
      "result produce time in seconds: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/da/anaconda2/lib/python2.7/site-packages/pandas/core/frame.py:2697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  **kwargs)\n",
      "output_check2.py:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_marg_size['persons']=sum_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18.6726429462\n",
      "memory result end 151089152\n",
      "\n",
      "phase =  1 \n",
      "\n",
      "Synthesizing at geog level: 'block_group' (number of geographies is 627)\n",
      "memory 1 145756160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/da/anaconda2/lib/python2.7/site-packages/pandas/core/frame.py:2705: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  **kwargs)\n",
      "output_check2.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  dfhh7size['hh_size_weight_7']=dfhh7size['persons']/dfhh7size['households']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiprocessing time in seconds:  19.5994870663\n",
      "memory multiprocessing end 164040704\n",
      "result produce time in seconds:  19.6538219452\n",
      "memory result end 164040704\n",
      "\n",
      "phase =  2 \n",
      "\n",
      "Synthesizing at geog level: 'block_group' (number of geographies is 627)\n",
      "memory 1 150106112\n",
      "multiprocessing time in seconds:  20.3050680161\n",
      "memory multiprocessing end 163823616\n",
      "result produce time in seconds:  20.3579189777\n",
      "memory result end 163823616\n",
      "76.2619900703\n"
     ]
    }
   ],
   "source": [
    "###for selected BGs\n",
    "#enable_logging()\n",
    "time0=time.time()\n",
    "geoname=\"problembgs3.csv\"\n",
    "pathout=outputfolder+geoname+\"_starter%s_\"%(starter_ver)\n",
    "\n",
    "dfbg=pd.read_csv(geoname,index_col=None,dtype=str) #make sure csv column in text not number, so read as'099' not 99\n",
    "indd=[ind for i, ind in dfbg.iterrows()]\n",
    "phases=3\n",
    "finalcheck=[]\n",
    "for phase in range(phases):\n",
    "    print \"\\nphase = \", phase, \"\\n\"\n",
    "    starter = Starter(os.environ[\"CENSUS\"], \"MI\", 'Macomb County', phase=phase)\n",
    "    households, persons, fit, hh_marginal, pp_marginal = synthesize_all(starter, indexes=indd)\n",
    "    \n",
    "    #HHs and Persons output\n",
    "    if phase == phases-1:\n",
    "        households.to_csv(pathout+'_households.csv')\n",
    "        persons.to_csv(pathout+'_persons.csv')\n",
    " \n",
    "    ##process check tables\n",
    "    dict_check=output_check({'households':[hh_marginal,households], 'persons':[pp_marginal,persons]})\n",
    "    #print dict_check.keys() #['households', 'persons', 'hhsize', 'person_factor', 'hhsize7plus']\n",
    "    \n",
    "    outfiles=[pathout+\"_check_households.csv\",pathout+\"_check_households_bycat.csv\", \\\n",
    "              pathout+\"_check_persons.csv\",pathout+\"_check_persons_bycat.csv\", \\\n",
    "              pathout+\"_check_hhsize.csv\"]\n",
    "\n",
    "    #set index to check tables and rename columns with phase #\n",
    "    dfcheck=[dict_check['households'][0],dict_check['households'][1], \\\n",
    "             dict_check['persons'][0],dict_check['persons'][1], \\\n",
    "             dict_check['hhsize']]\n",
    "    indx=['state','county','tract','block group','cat_name']\n",
    "    indxl=[indx, indx+['cat_value']]*2+[indx+['hh_size']]\n",
    "\n",
    "    for ind, df in zip(indxl, dfcheck):\n",
    "        df.set_index(ind, inplace=True)\n",
    "        df.rename(columns={col:col+\"_\"+str(phase) for col in df.columns}, inplace=True)\n",
    "\n",
    "    #join check table from multiple runs            \n",
    "    if len(finalcheck)==0:\n",
    "        finalcheck=dfcheck\n",
    "    else:\n",
    "        for i in range(5):\n",
    "            finalcheck[i]=pd.merge(finalcheck[i], dfcheck[i], left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    #create additional id fields for analysis purpose  \n",
    "    if phase == phases-1:\n",
    "        for i in range(5):\n",
    "            finalcheck[i].reset_index(inplace=True)\n",
    "            finalcheck[i]['bg10']=finalcheck[i]['tract']+finalcheck[i]['block group']\n",
    "            finalcheck[i]['geoid10']=finalcheck[i]['state']+finalcheck[i]['county']+ \\\n",
    "                                        finalcheck[i]['tract']+finalcheck[i]['block group']  \n",
    "            finalcheck[i].to_csv(outfiles[i])\n",
    "\n",
    "    if phase == 0:\n",
    "        dict_check['hhsize7plus'].to_csv(\"hh7_persons_drawing.csv\")\n",
    "    if phase == 1:\n",
    "        dict_check['person_factor'].to_csv(\"hh_size_person_factor.csv\")\n",
    "    if phase == 2:\n",
    "        os.rename(\"hh7_persons_drawing.csv\", pathout+\"_hh7_persons_drawing.csv\")\n",
    "        os.rename(\"hh_size_person_factor.csv\", pathout+\"_hh_size_person_factor.csv\")\n",
    "        \n",
    "    households,persons,marginals,dict_check = None, None, None, None\n",
    "    \n",
    "print time.time()-time0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chisquare([18, 7, 42, 33],[15, 10, 45, 30],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from synthpop.draw import compare_to_constraints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=pd.Series([18, 7, 42, 33,33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b=pd.Series([15, 15, 10, 45, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_to_constraints(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.align(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if a_list:\n",
    "    print 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a[b>=15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'],\n",
    "       ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]\n",
    "tuples = list(zip(*arrays))\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\n",
    "s = pd.Series(np.random.randn(8),index=index)\n",
    "s=s.to_frame(name='col1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s['col2']=s['col1']+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for name, group in s.groupby(level=range(2)):\n",
    "    print name\n",
    "    print type(group['col1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chisquare([16, 18, 16, 14, 12, 12], f_exp=[16, 16, 16, 16, 16, 8],ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chisquare([18, 7, 42,33], f_exp=[15, 10, 45, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dk=pd.DataFrame.from_dict({'a':[1 ,2],'b':[3,4] },orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print dk.index.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a={'households':[1,2], 'persons':[3,4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k,v in a.keys(),a.values():\n",
    "    print k\n",
    "    print v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b.keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {'Column 1'     : [1., 2., 3., 4.],\n",
    "        'Index Title'  : [\"Apples\", \"Oranges\", \"Puppies\", \"Ducks\"]}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.index.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'A': ['foo', 'bar', 'foo', 'bar',\n",
    "                         'foo', 'bar', 'foo', 'foo'],\n",
    "                   'B': ['one', 'one', 'two', 'three',\n",
    "                         'two', 'two', 'one', 'three'],\n",
    "                   'number A': np.arange(8),\n",
    "                   'number B': np.arange(8) * 2})\n",
    "grouped = df.groupby('A')\n",
    "\n",
    "print(grouped.agg({\n",
    "    'number A': 'sum',\n",
    "    'number B': 'min'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(grouped.agg({\n",
    "    'number A': 'sum',\n",
    "    'number B': 'min'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped.agg({\n",
    "    'number A': 'sum',\n",
    "    'number B': 'min'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat[]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat=[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in [*[1,2],*[3,4],5]:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if a_list:\n",
    "    print 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[[2],[3]+[4]]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
