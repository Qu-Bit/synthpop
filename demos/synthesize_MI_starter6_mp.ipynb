{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import multiprocessing as mp\n",
    "\n",
    "from output_check2 import output_check\n",
    "from synthpop.recipes.starter6 import Starter\n",
    "starter_ver='6'\n",
    "\n",
    "from synthpop.synthesizer import synthesize_all, enable_logging \n",
    "import pandas as pd\n",
    "import os,time,datetime\n",
    "import pickle\n",
    "\n",
    "import gc\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputfolder = '/home/da/tools/synthpop/demos/outputs/'\n",
    "hdfpath = outputfolder+\"starter%s_\"%(starter_ver)+time.strftime(\"%Y%m%d-%H%M\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesize by county "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for whole county\n",
    "time0=time.time()\n",
    "print str( datetime.datetime.now())\n",
    "results=[]\n",
    "\n",
    "store = pd.HDFStore(hdfpath+'.h5',complevel=9, complib='blosc')\n",
    "\n",
    "#synthesize_counties([\"Livingston County\",\"Oakland County\",\"Washtenaw County\",\n",
    "#\"Wayne County\",\"Monroe County\",\"Macomb County\",\"St. Clair County\"])\n",
    "\n",
    "if __name__=='__main__':\n",
    "    counties=[\"Wayne County\"]\n",
    "\n",
    "    for county in counties:\n",
    "        finalcheck=[]\n",
    "        phases=3\n",
    "        df_check=None\n",
    "        \n",
    "        for phase in range(phases):\n",
    "            print \"\\n county = \",county,\" phase = \", phase, \"\\n\"\n",
    "            \n",
    "            pathout = county.replace(\" \",\"_\") #output name in hdf\n",
    "            \n",
    "            starter = Starter(os.environ[\"CENSUS\"], \"MI\", county, phase = phase)\n",
    "           \n",
    "            households, persons, fit, hh_marginal, pp_marginal = synthesize_all(starter)\n",
    "\n",
    "            #households.index.name='hh_id' #result[0] is hh\n",
    "            #households['serialno'] = households['serialno'].map(lambda x: '%f' % x)\n",
    "            #persons['serialno'] = persons['serialno'].map(lambda x: '%f' % x)\n",
    "            #results[0].to_csv(outputfolder+county+\"_starter%s_\"%('3')+\"HHs.csv\",float_format='%.f') #float_format, \n",
    "            #          not use scentific, pplies to all fp numbers \n",
    "            #could use results['serialno'] = results['serialno'].map(lambda x: '%f' % x) to change \n",
    "            #         output format for serialno only\n",
    "            \n",
    "            #HHs and Persons output\n",
    "            if phase == phases-1:\n",
    "                store[pathout+'_households'] = households\n",
    "                store[pathout+'_persons'] = persons\n",
    "\n",
    "            ##process check tables\n",
    "            dict_check = output_check({'households':[hh_marginal,households], \n",
    "                                       'persons':[pp_marginal,persons]\n",
    "                                      })\n",
    "\n",
    "\n",
    "            ##outfiles=[pathout+\"_check_households.csv\",pathout+\"_check_households_bycat.csv\", \\\n",
    "            ##          pathout+\"_check_persons.csv\",pathout+\"_check_persons_bycat.csv\", \\\n",
    "            ##          pathout+\"_check_hhsize.csv\"]\n",
    "            \n",
    "            outfiles = [pathout+\"_check_households\", \n",
    "                        pathout+\"_check_households_bycat\", \n",
    "                        pathout+\"_check_persons\", \n",
    "                        pathout+\"_check_persons_bycat\",\n",
    "                        pathout+\"_check_hhsize\"]\n",
    "            \n",
    "            #set index to check tables and rename columns with phase #\n",
    "            dfcheck = [dict_check['households'][0],\n",
    "                       dict_check['households'][1],\n",
    "                       dict_check['persons'][0],\n",
    "                       dict_check['persons'][1],\n",
    "                       dict_check['hhsize']]\n",
    "            indx = ['state','county','tract','block group','cat_name']\n",
    "            indxl = [indx, indx+['cat_value']]*2+[indx+['hh_size']]\n",
    "\n",
    "            for ind, df in zip(indxl, dfcheck):\n",
    "                df.set_index(ind, inplace=True)\n",
    "                df.rename(columns = { col:col+\"_\"+str(phase) for col in df.columns}, inplace = True )\n",
    "\n",
    "            #join check table from multiple runs            \n",
    "            if len(finalcheck) == 0:\n",
    "                finalcheck = dfcheck\n",
    "            else:\n",
    "                for i in range(5):\n",
    "                    finalcheck[i] = pd.merge(finalcheck[i], dfcheck[i], \\\n",
    "                                             left_index = True, right_index = True, how = 'left')\n",
    "\n",
    "            #create additional id fields for analysis purpose  \n",
    "            if phase == phases-1:\n",
    "                for i in range(5):\n",
    "                    finalcheck[i].reset_index(inplace = True)\n",
    "                    finalcheck[i]['bg10'] = finalcheck[i]['tract']+finalcheck[i]['block group']\n",
    "                    finalcheck[i]['geoid10'] = finalcheck[i]['state']+finalcheck[i]['county']+ \n",
    "                                                finalcheck[i]['tract']+finalcheck[i]['block group']  \n",
    "                    store[outfiles[i]]=finalcheck[i]\n",
    "\n",
    "            if phase == 0:\n",
    "                dict_check['hhsize7plus'].to_csv(\"hh7_persons_drawing.csv\")\n",
    "            if phase == 1:\n",
    "                dict_check['person_factor'].to_csv(\"hh_size_person_factor.csv\")\n",
    "            if phase == 2:\n",
    "                df = pd.read_csv(\"hh7_persons_drawing.csv\")\n",
    "                store[pathout+\"_hh7_persons_drawing\"] = df\n",
    "                df = pd.read_csv(\"hh_size_person_factor.csv\")\n",
    "                store[pathout+\"_hh_size_person_factor\"] = df               \n",
    "                #os.rename(\"hh7_persons_drawing.csv\", pathout+\"_hh7_persons_drawing.csv\")\n",
    "                #os.rename(\"hh_size_person_factor.csv\", pathout+\"_hh_size_person_factor.csv\")\n",
    "\n",
    "                \n",
    "            newhh, newpop = postprocess(households, persons)\n",
    "            store[pathout+\"sim_households\"] = newhh\n",
    "            store[pathout+\"sim_persons\"] = newpop\n",
    "            \n",
    "            households, persons, marginals, dict_check, newhh, newpop = None, None, None, None, None, None\n",
    "            \n",
    "\n",
    "            with open(pathout+'_fit_stats.pkl', 'wb') as f:\n",
    "                pickle.dump(fit, f)\n",
    "\n",
    "            #del households,persons,hh_marginal,pp_marginal,dict_check, dfcheck\n",
    "            \n",
    "            gc.collect()  \n",
    "            \n",
    "store.close()            \n",
    "print 'total time', datetime.timedelta(seconds=(time.time()-time0))\n",
    "print str( datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#combine output if there are multiple hdfs\n",
    "store0=pd.HDFStore(outputfolder+'starter6_20160823.h5',complevel=9, complib='blosc')\n",
    "lst_st=[outputfolder+'starter6_20160822-0938.h5',\n",
    "        outputfolder+'starter6_20160823-0804.h5',\n",
    "       outputfolder+'starter6_20160823-0922.h5']\n",
    "\n",
    "for st in  lst_st:\n",
    "    print st\n",
    "    sts=pd.HDFStore(st)\n",
    "    for item in sts:\n",
    "        print '    ',item\n",
    "        store0[item[1:]]=sts[item]\n",
    "    sts.close()\n",
    "    \n",
    "store0.close()\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# post process Synthesizer results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Livingston County_households\n",
      "/Macomb County_households\n",
      "/Monroe County_households\n",
      "/Oakland County_households\n",
      "/St. Clair County_households\n",
      "/Washtenaw County_households\n",
      "/Wayne County_households\n",
      "/Livingston County_persons\n",
      "/Macomb County_persons\n",
      "/Monroe County_persons\n",
      "/Oakland County_persons\n",
      "/St. Clair County_persons\n",
      "/Washtenaw County_persons\n",
      "/Wayne County_persons\n",
      "all done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/da/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:30: FutureWarning: using '+' to provide set union with Indexes is deprecated, use '|' or .union()\n"
     ]
    }
   ],
   "source": [
    "hdf_input = r\"./outputs/starter6_2016-07-12_region.h5\"\n",
    "hdf_output= hdf_input.replace('.h5', '_syn.h5')\n",
    "directory = outputfolder\n",
    "\n",
    "# directory = \"\"\n",
    "h_name = 'syn_households'\n",
    "p_name = 'syn_persons'\n",
    "\n",
    "syn_hdf = pd.HDFStore(hdf_input, mode=\"r\") \n",
    "out_hdf = pd.HDFStore(hdf_output, complevel=9, complib='blosc', mode=\"w\") \n",
    "\n",
    "def default_cleaner(df):\n",
    "    df.columns = [x.lower() for x in df.columns]\n",
    "    df.index.names = [(None if x is None else x.lower()) for x in df.index.names]\n",
    "    types = df.apply(lambda x: pd.lib.infer_dtype(x.values))\n",
    "    for col in types[types == 'unicode'].index:\n",
    "        df[col] = df[col].astype(str)\n",
    "    df.columns = [str(c) for c in df.columns]\n",
    "    return df\n",
    "\n",
    "def sym_cleaner(df):\n",
    "    df = default_cleaner(df)\n",
    "    types = df.dtypes\n",
    "    for col in types[types == np.int64].index:\n",
    "        df[col] = df[col].astype(float)\n",
    "\n",
    "    df[\"county\"] = df.county.astype(int)\n",
    "    if 'hh_id' in df:\n",
    "        df.hh_id += df.county * 10**7\n",
    "    df.index += df.county * 10**7\n",
    "    return df\n",
    "\n",
    "\n",
    "if h_name in out_hdf:\n",
    "    del out_hdf[h_name]\n",
    "\n",
    "for f in syn_hdf:\n",
    "    if f.endswith(\"County_households\"):\n",
    "        gc.collect()\n",
    "        print f\n",
    "        data = sym_cleaner(syn_hdf[f][['ADJINC', 'NP', 'block group', 'VEH', 'NOC',\n",
    "                                       'county', 'age_of_head', 'race_of_head', 'hispanic_head',\n",
    "                                       'state', 'tract', 'workers',\n",
    "                                       # for placement\n",
    "                                       'YBL', 'BLD', 'VALP', 'GRNTP', 'HINCP', \"hh_tenure_agehead\", \"ADJHSG\"\n",
    "                                       ]]\n",
    "                           )\n",
    "\n",
    "        data.rename(columns={'hincp': 'income', \n",
    "                             'grntp': 'rent',\n",
    "                             'np': 'persons',\n",
    "                             'race_of_head': 'race_id',\n",
    "                             'veh': 'cars',\n",
    "                             'noc': 'children'\n",
    "                             }, inplace=True)\n",
    "\n",
    "\n",
    "        data.loc[data.race_id > 2, 'race_id'] = 4\n",
    "        data.loc[data.hispanic_head == 'yes', 'race_id'] = 3\n",
    "        del data['hispanic_head']\n",
    "\n",
    "        data[\"income\"] *= data[\"adjinc\"] / 1000000.0\n",
    "        del data['adjinc']\n",
    "\n",
    "        data[\"rent\"] *= data[\"adjhsg\"] / 1000000.0\n",
    "        del data['adjhsg']\n",
    "\n",
    "        data.index.name = \"household_id\"\n",
    "        \n",
    "        #update number of workers from persons table since only family workers counted in HH table\n",
    "        datap = syn_hdf[f.replace('households', 'persons')][['ESR','AGEP', 'hh_id']]\n",
    "        datap['worker'] = 0\n",
    "        datap.loc[datap.ESR.isin(range(1,6)),'worker'] = 1\n",
    "        data['workers'] = datap.groupby('hh_id').worker.sum()\n",
    "        \n",
    "        #update number of childrens(AGEP<18) from persons table since NOC has only\n",
    "        datap['child'] = 0\n",
    "        datap.loc[(datap.AGEP<18),'child'] = 1\n",
    "        data['children'] = datap.groupby('hh_id').child.sum()\n",
    "        \n",
    "        data.to_hdf(out_hdf, h_name, format='t', append=True, min_itemsize=2 ** 7)\n",
    "    \n",
    "        \n",
    "if p_name in out_hdf:\n",
    "    del out_hdf[p_name]\n",
    "\n",
    "for f in syn_hdf:\n",
    "    if f.endswith(\"County_persons\"):\n",
    "        gc.collect()\n",
    "        print f\n",
    "        data = sym_cleaner(syn_hdf[f][['county', 'AGEP', 'RELP', 'SEX', 'SPORDER', 'hh_id', 'HISP', 'RAC1P']])\n",
    "        data.rename(\n",
    "            columns={'agep': 'age',\n",
    "                     'rac1p': 'race_id',\n",
    "                     'relp': 'relate',\n",
    "                     'sporder': 'member_id',\n",
    "                     'hh_id': 'household_id'}, inplace=True)\n",
    "        del data['county']\n",
    "\n",
    "        data.loc[data.race_id > 2, 'race_id'] = 4\n",
    "        data.loc[data.hisp > 1, 'race_id'] = 3\n",
    "        del data['hisp']\n",
    "\n",
    "        data.index.name = \"person_id\"\n",
    "        data.to_hdf(out_hdf, p_name, format='t', append=True, min_itemsize=2 ** 7)\n",
    "\n",
    "\n",
    "syn_hdf.close()\n",
    "out_hdf.close()\n",
    "print 'all done'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesize by selected Block Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###for selected BGs\n",
    "#enable_logging()\n",
    "time0=time.time()\n",
    "geoname=\"problembgs3.csv\"\n",
    "pathout=outputfolder+geoname+\"_starter%s_\"%(starter_ver)\n",
    "\n",
    "dfbg=pd.read_csv(geoname,index_col=None,dtype=str) #make sure csv column in text not number, so read as'099' not 99\n",
    "indd=[ind for i, ind in dfbg.iterrows()]\n",
    "phases=3\n",
    "finalcheck=[]\n",
    "for phase in range(phases):\n",
    "    print \"\\nphase = \", phase, \"\\n\"\n",
    "    starter = Starter(os.environ[\"CENSUS\"], \"MI\", 'Macomb County', phase=phase)\n",
    "    households, persons, fit, hh_marginal, pp_marginal = synthesize_all(starter, indexes=indd)\n",
    "    \n",
    "    #HHs and Persons output\n",
    "    if phase == phases-1:\n",
    "        households.to_csv(pathout+'_households.csv')\n",
    "        persons.to_csv(pathout+'_persons.csv')\n",
    " \n",
    "    ##process check tables\n",
    "    dict_check=output_check({'households':[hh_marginal,households], 'persons':[pp_marginal,persons]})\n",
    "    #print dict_check.keys() #['households', 'persons', 'hhsize', 'person_factor', 'hhsize7plus']\n",
    "    \n",
    "    outfiles=[pathout+\"_check_households.csv\",pathout+\"_check_households_bycat.csv\", \\\n",
    "              pathout+\"_check_persons.csv\",pathout+\"_check_persons_bycat.csv\", \\\n",
    "              pathout+\"_check_hhsize.csv\"]\n",
    "\n",
    "    #set index to check tables and rename columns with phase #\n",
    "    dfcheck=[dict_check['households'][0],dict_check['households'][1], \\\n",
    "             dict_check['persons'][0],dict_check['persons'][1], \\\n",
    "             dict_check['hhsize']]\n",
    "    indx=['state','county','tract','block group','cat_name']\n",
    "    indxl=[indx, indx+['cat_value']]*2+[indx+['hh_size']]\n",
    "\n",
    "    for ind, df in zip(indxl, dfcheck):\n",
    "        df.set_index(ind, inplace=True)\n",
    "        df.rename(columns={col:col+\"_\"+str(phase) for col in df.columns}, inplace=True)\n",
    "\n",
    "    #join check table from multiple runs            \n",
    "    if len(finalcheck)==0:\n",
    "        finalcheck=dfcheck\n",
    "    else:\n",
    "        for i in range(5):\n",
    "            finalcheck[i]=pd.merge(finalcheck[i], dfcheck[i], left_index=True, right_index=True, how='left')\n",
    "    \n",
    "    #create additional id fields for analysis purpose  \n",
    "    if phase == phases-1:\n",
    "        for i in range(5):\n",
    "            finalcheck[i].reset_index(inplace=True)\n",
    "            finalcheck[i]['bg10']=finalcheck[i]['tract']+finalcheck[i]['block group']\n",
    "            finalcheck[i]['geoid10']=finalcheck[i]['state']+finalcheck[i]['county']+ \\\n",
    "                                        finalcheck[i]['tract']+finalcheck[i]['block group']  \n",
    "            finalcheck[i].to_csv(outfiles[i])\n",
    "\n",
    "    if phase == 0:\n",
    "        dict_check['hhsize7plus'].to_csv(\"hh7_persons_drawing.csv\")\n",
    "    if phase == 1:\n",
    "        dict_check['person_factor'].to_csv(\"hh_size_person_factor.csv\")\n",
    "    if phase == 2:\n",
    "        os.rename(\"hh7_persons_drawing.csv\", pathout+\"_hh7_persons_drawing.csv\")\n",
    "        os.rename(\"hh_size_person_factor.csv\", pathout+\"_hh_size_person_factor.csv\")\n",
    "        \n",
    "    households,persons,marginals,dict_check = None, None, None, None\n",
    "    \n",
    "print time.time()-time0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
